{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, inspect, sys\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PIL\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from dataset import NormalizedDataset, IncompleteDataset, MinstWrapper, get_stats, get_loaders\n",
    "from classification import Conv_Net, CNNClassifier\n",
    "import pickle\n",
    "from skimage.morphology import dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = 255\n",
    "black = 0\n",
    "\n",
    "def inverse_color(img):\n",
    "    return PIL.Image.eval(img, lambda val: 255 - val)\n",
    "\n",
    "def fix_background_color_bug(img):\n",
    "    colors = sorted(img.getcolors(), key=lambda pair: pair[0], reverse=True)\n",
    "    replace_color = colors[0][1]\n",
    "    remove_color = colors[2][1] if colors[2][1] < colors[1][1] else colors[1][1]\n",
    "\n",
    "    data = np.array(img)\n",
    "    data[data == remove_color] = replace_color\n",
    "    return PIL.Image.fromarray(data)\n",
    "\n",
    "def remove_background(img):\n",
    "    return PIL.Image.eval(img, lambda val: 0 if val < (256/2) else val)\n",
    "\n",
    "def to_binary(img):\n",
    "    return PIL.Image.eval(img, lambda val: 255 if val < (256/2) else 0)\n",
    "\n",
    "def to_dilated(img):\n",
    "    return PIL.Image.fromarray(dilation(np.array(img)))\n",
    "\n",
    "def get(name):\n",
    "    try:\n",
    "        with open('{}.pickle'.format(name), 'rb') as handle:\n",
    "            return pickle.load(handle)\n",
    "    except FileNotFoundError:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_image = False\n",
    "\n",
    "## Rotation, Brightness and Resizing\n",
    "random_transforms = [\n",
    "    transforms.RandomRotation(360, fill=black),\n",
    "    transforms.RandomAffine(0, shear=15, scale=(0.8, 0.95), translate=(.03, .03)),\n",
    "]\n",
    "\n",
    "format_transforms = [transforms.Lambda(to_dilated)]\n",
    "\n",
    "if not binary_image:\n",
    "    random_transforms.append(transforms.ColorJitter(brightness=(0.9, 1), contrast=(0.7, 1)))\n",
    "else:\n",
    "    format_transforms.append(transforms.Lambda(to_binary))\n",
    "\n",
    "all_transforms = transforms.Compose(random_transforms + format_transforms)\n",
    "\n",
    "video_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Lambda(inverse_color),\n",
    "    transforms.Lambda(remove_background),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.Compose(format_transforms),\n",
    "])\n",
    "\n",
    "minst_tensor_transform = transforms.Compose([\n",
    "    all_transforms,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "video_tensor_transform = transforms.Compose([\n",
    "    video_transform,\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABJUlEQVR4nGPkYMANmPDIUU1SaamkExKXEdlBSs3cDAzHpjN8xiLJ2yUJYcR6rcTUaV4JY52a8Y6BgYEF2crLcJYZw087f1SdjFmuUNa/t2IMDMtRXJvwjYGB4eZvBoZ/b0X/M/wKRpFcrnSZ4XJ98e/ve+cdZ/jOsBbFzh8Mugy6vx4V+05lYNiQsAzVToblDJyvN2yFsKWfooXQRIZvoqneEPZT9OB7fpOLgSGVEcaFSgpCqIfIHAYGJoZ49XLecgZdQf+Z0mkKty4wMDCECcH8nc4QyMDA8FzyicxLcQYGhr/MDAwX62GSHBsY0EEAwtgAdLlaXSQHBQQwPEZI/T2HCH9oIMT9892svSFofcXtz00IhbAQ4vnCwPGD/SeqBYwDkG4BdKZMNC1FkasAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x122B34588>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minst Dataset\n",
    "minst_dataset = MinstWrapper(datasets.MNIST(\"../\", transform=minst_tensor_transform, download=True))\n",
    "\n",
    "# Show example image\n",
    "datasets.MNIST(\"../\", transform=all_transforms, download=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1592118889093399 0.29127004742622375\n"
     ]
    }
   ],
   "source": [
    "minst_mean, minst_std = get_stats(minst_dataset)\n",
    "print(minst_mean, minst_std)\n",
    "minst_dataset = NormalizedDataset(minst_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 120)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating train and test loader from MINST\n",
    "train_loader, test_loader = get_loaders(minst_dataset, validation_split=0.2)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing test set\n",
    "images = [x[0] for x in get(\"../digits\")]\n",
    "labels = [\"3\", \"2\", \"7\", \"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th epoch, train acc: 0.527458, val acc: 0.689750, test acc: 0.000000\n",
      "2th epoch, train acc: 0.767479, val acc: 0.809500, test acc: 0.000000\n",
      "3th epoch, train acc: 0.824917, val acc: 0.844417, test acc: 0.000000\n",
      "4th epoch, train acc: 0.853687, val acc: 0.862917, test acc: 0.000000\n",
      "5th epoch, train acc: 0.866938, val acc: 0.879250, test acc: 0.000000\n",
      "6th epoch, train acc: 0.877583, val acc: 0.869250, test acc: 0.000000\n",
      "7th epoch, train acc: 0.885604, val acc: 0.881500"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Conv_Net(nb_hidden=100, nb_conv3=128, nb_out=10)\n",
    "\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Defining the optimizer for GD\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n",
    "\n",
    "# Defining the criterion to calculate loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "nb_epochs = 200\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "# Temporary classifier for testing\n",
    "CNNClassifier(\"digits\", path=\"../\", minst_binary=False)\n",
    "\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "    acc = 0\n",
    "    model.train()\n",
    "    for train_input, train_target in train_loader:\n",
    "\n",
    "        # Model computations\n",
    "        output = model(train_input)\n",
    "        loss = criterion(output, train_target) \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tmp_acc = 0\n",
    "        for tensor, target in zip(output, train_target):\n",
    "            _, index = tensor.max(0)\n",
    "            if index == target:\n",
    "                tmp_acc += 1\n",
    "                \n",
    "        tmp_acc /= len(output)\n",
    "        acc += tmp_acc \n",
    "        \n",
    "    acc /= len(train_loader)\n",
    "        \n",
    "    should_print = e%1 == 0\n",
    "    if should_print:\n",
    "        print('%dth epoch, train acc: %f' % (e+1, acc), end=\"\")\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    for test_input, test_target in test_loader:\n",
    "        \n",
    "        output = model(test_input)\n",
    "        loss = criterion(output, test_target) \n",
    "        \n",
    "        tmp_acc = 0\n",
    "        for tensor, target in zip(output, test_target):\n",
    "            _, index = tensor.max(0)\n",
    "            if index == target:\n",
    "                tmp_acc += 1\n",
    "#             elif should_print:\n",
    "#                 pass\n",
    "#                 print(\", {} != {}\".format(index, target), end=\"\")\n",
    "                \n",
    "        tmp_acc /= len(output)\n",
    "        acc += tmp_acc \n",
    "                \n",
    "    acc /= len(test_loader)\n",
    "    print(\", val acc: %f\" % (acc), end=\"\")\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), \"../digit_model\")\n",
    "    \n",
    "    test_losses.append(loss)\n",
    "    \n",
    "    test_acc = 0\n",
    "    classifier.model = model\n",
    "    for (img, label) in zip(images, labels):\n",
    "        prediction = classifier.predict(img)\n",
    "        if prediction == label:\n",
    "            test_acc += 1\n",
    "\n",
    "    test_acc /= len(images)\n",
    "    print(\", test acc: %f\" % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1th epoch, train acc: 0.408792, val acc: 0.523917, test acc: 0.000000\n",
    "# 2th epoch, train acc: 0.605125, val acc: 0.643417, test acc: 0.000000\n",
    "# 3th epoch, train acc: 0.678979, val acc: 0.713083, test acc: 0.000000\n",
    "# 4th epoch, train acc: 0.727250, val acc: 0.750083, test acc: 0.000000\n",
    "# 5th epoch, train acc: 0.762021, val acc: 0.773583, test acc: 0.000000\n",
    "# 6th epoch, train acc: 0.780417, val acc: 0.791583, test acc: 0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1th epoch, train acc: 0.338646, test acc: 0.456000\n",
    "# 2th epoch, train acc: 0.531000, test acc: 0.577000\n",
    "# 3th epoch, train acc: 0.606146, test acc: 0.632833\n",
    "# 4th epoch, train acc: 0.651458, test acc: 0.668083\n",
    "# 5th epoch, train acc: 0.683938, test acc: 0.694417\n",
    "# 6th epoch, train acc: 0.708542, test acc: 0.713000\n",
    "# 7th epoch, train acc: 0.728292, test acc: 0.729167\n",
    "# 8th epoch, train acc: 0.743021, test acc: 0.750583\n",
    "# 9th epoch, train acc: 0.755292, test acc: 0.763833\n",
    "# 10th epoch, train acc: 0.764208, test acc: 0.763917\n",
    "# 11th epoch, train acc: 0.773229, test acc: 0.778083\n",
    "# 12th epoch, train acc: 0.781708, test acc: 0.785333\n",
    "# 13th epoch, train acc: 0.786958, test acc: 0.785750\n",
    "# 14th epoch, train acc: 0.795396, test acc: 0.795500\n",
    "# 15th epoch, train acc: 0.798271, test acc: 0.791750\n",
    "# 16th epoch, train acc: 0.801896, test acc: 0.808917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
