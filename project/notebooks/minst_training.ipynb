{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, inspect, sys\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PIL\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from dataset import NormalizedDataset, IncompleteDataset, MinstWrapper, get_stats, get_loaders\n",
    "from classification import Conv_Net, CNNClassifier\n",
    "import pickle\n",
    "from skimage.morphology import dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = 255\n",
    "black = 0\n",
    "\n",
    "def inverse_color(img):\n",
    "    return PIL.Image.eval(img, lambda val: 255 - val)\n",
    "\n",
    "def fix_background_color_bug(img):\n",
    "    colors = sorted(img.getcolors(), key=lambda pair: pair[0], reverse=True)\n",
    "    replace_color = colors[0][1]\n",
    "    remove_color = colors[2][1] if colors[2][1] < colors[1][1] else colors[1][1]\n",
    "\n",
    "    data = np.array(img)\n",
    "    data[data == remove_color] = replace_color\n",
    "    return PIL.Image.fromarray(data)\n",
    "\n",
    "def remove_background(img):\n",
    "    return PIL.Image.eval(img, lambda val: 0 if val < (256/2) else val)\n",
    "\n",
    "def to_binary(img):\n",
    "    return PIL.Image.eval(img, lambda val: 255 if val < (256/2) else 0)\n",
    "\n",
    "def to_dilated(img):\n",
    "    return PIL.Image.fromarray(dilation(np.array(img)))\n",
    "\n",
    "def get(name):\n",
    "    try:\n",
    "        with open('{}.pickle'.format(name), 'rb') as handle:\n",
    "            return pickle.load(handle)\n",
    "    except FileNotFoundError:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_image = False\n",
    "\n",
    "## Rotation, Brightness and Resizing\n",
    "random_transforms = [\n",
    "    transforms.RandomRotation(360, fill=black),\n",
    "    transforms.RandomAffine(0, shear=15, scale=(0.8, 0.95), translate=(.03, .03)),\n",
    "]\n",
    "\n",
    "format_transforms = [transforms.Lambda(to_dilated)]\n",
    "\n",
    "if not binary_image:\n",
    "    random_transforms.append(transforms.ColorJitter(brightness=(0.9, 1), contrast=(0.7, 1)))\n",
    "else:\n",
    "    format_transforms.append(transforms.Lambda(to_binary))\n",
    "\n",
    "all_transforms = transforms.Compose(random_transforms + format_transforms)\n",
    "\n",
    "video_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Lambda(inverse_color),\n",
    "    transforms.Lambda(remove_background),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.Compose(format_transforms),\n",
    "])\n",
    "\n",
    "minst_tensor_transform = transforms.Compose([\n",
    "    all_transforms,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "video_tensor_transform = transforms.Compose([\n",
    "    video_transform,\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABG0lEQVR4nKXSsUsCcRTA8e9PwowWpSXSJTAOinJJnOIG/4CbbhAck5aGlqKxvRap4Zag3Cqkv6DBJbKGptpCKAjOFh1OrhBs+N3lT71fEP2W94MPj/d474k4+hf7xYZor+jRpjSpIV7ljJIWdwwMLZ4/0CzosJIf5BLyO6w9JUM5j5jebEBKbMNTgCIYQtmCfsNJmWurYI/h7Bn0d+c2TABe9lUUlwDPH2aQIzVs6A5g2fShDnBdUHDLkzHhH90CWI8KOkUZ/ZPmawdYGmlo/hhuehdJFxaqwOG9UnNmj1On9ukC7zUgq2ay2PbCwSQP0nxVeso+Wz9GJg1xi+hLeHMDiMJuC1jXIA6Q0aGHHH709dlyMeL/d/tn/AbfLj6026eKTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1391AC5C0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minst Dataset\n",
    "minst_dataset = MinstWrapper(datasets.MNIST(\"../\", transform=minst_tensor_transform, download=True))\n",
    "\n",
    "# Show example image\n",
    "datasets.MNIST(\"../\", transform=all_transforms, download=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15896999835968018 0.2910420000553131\n"
     ]
    }
   ],
   "source": [
    "minst_mean, minst_std = get_stats(minst_dataset)\n",
    "print(minst_mean, minst_std)\n",
    "minst_dataset = NormalizedDataset(minst_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating train and test loader from MINST\n",
    "train_loader, test_loader = get_loaders(minst_dataset, validation_split=0.2)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing test set\n",
    "images = [x[0] for x in get(\"../digits\")]\n",
    "labels = [\"3\", \"2\", \"7\", \"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th epoch, train acc: 0.520562, val acc: 0.702833, test acc: 0.750000, test acc (with median): 0.750000\n",
      "2th epoch, train acc: 0.749917, val acc: 0.814333, test acc: 0.500000, test acc (with median): 0.500000\n",
      "3th epoch, train acc: 0.815333, val acc: 0.840250, test acc: 0.250000, test acc (with median): 0.250000\n",
      "4th epoch, train acc: 0.841729, val acc: 0.864583, test acc: 0.500000, test acc (with median): 0.250000\n",
      "5th epoch, train acc: 0.861042, val acc: 0.873417, test acc: 0.500000, test acc (with median): 0.500000\n",
      "6th epoch, train acc: 0.871438, val acc: 0.885000, test acc: 0.500000, test acc (with median): 0.500000\n",
      "7th epoch, train acc: 0.880375, val acc: 0.880833, test acc: 0.500000, test acc (with median): 0.500000\n",
      "8th epoch, train acc: 0.883667, val acc: 0.896667, test acc: 0.500000, test acc (with median): 0.250000\n",
      "9th epoch, train acc: 0.889313, val acc: 0.897917, test acc: 0.500000, test acc (with median): 0.250000\n",
      "10th epoch, train acc: 0.894187, val acc: 0.904917, test acc: 0.500000, test acc (with median): 0.500000\n",
      "11th epoch, train acc: 0.897458, val acc: 0.904417, test acc: 0.500000, test acc (with median): 0.750000\n",
      "12th epoch, train acc: 0.900750, val acc: 0.902167, test acc: 0.250000, test acc (with median): 0.250000\n",
      "13th epoch, train acc: 0.902438, val acc: 0.910583, test acc: 0.250000, test acc (with median): 0.500000\n",
      "14th epoch, train acc: 0.905146, val acc: 0.909917, test acc: 0.500000, test acc (with median): 0.500000\n",
      "15th epoch, train acc: 0.907958, val acc: 0.916417, test acc: 0.250000, test acc (with median): 0.500000\n",
      "16th epoch, train acc: 0.910333, val acc: 0.913750, test acc: 0.500000, test acc (with median): 0.750000\n",
      "17th epoch, train acc: 0.910417, val acc: 0.911750, test acc: 0.500000, test acc (with median): 0.750000\n",
      "18th epoch, train acc: 0.913396, val acc: 0.919083, test acc: 0.250000, test acc (with median): 0.500000\n",
      "19th epoch, train acc: 0.914292, val acc: 0.920000, test acc: 0.500000, test acc (with median): 0.750000\n",
      "20th epoch, train acc: 0.913979, val acc: 0.916500, test acc: 0.750000, test acc (with median): 0.750000\n",
      "21th epoch, train acc: 0.914812, val acc: 0.922083, test acc: 0.750000, test acc (with median): 0.750000\n",
      "22th epoch, train acc: 0.916771, val acc: 0.920583, test acc: 0.750000, test acc (with median): 0.500000\n",
      "23th epoch, train acc: 0.918146, val acc: 0.918583, test acc: 0.750000, test acc (with median): 0.750000\n",
      "24th epoch, train acc: 0.917958, val acc: 0.926083, test acc: 0.750000, test acc (with median): 0.500000\n",
      "25th epoch, train acc: 0.921229, val acc: 0.923833, test acc: 0.750000, test acc (with median): 0.500000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Conv_Net(nb_hidden=100, nb_conv3=128, nb_out=10)\n",
    "\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Defining the optimizer for GD\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n",
    "\n",
    "# Defining the criterion to calculate loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "nb_epochs = 200\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "# Temporary classifier for testing\n",
    "classifier = CNNClassifier(\"digits\", path=\"../\", minst_binary=binary_image)\n",
    "classifier_with_median = CNNClassifier(\"digits\", path=\"../\", minst_binary=binary_image, with_median_filter=True)\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "    acc = 0\n",
    "    model.train()\n",
    "    for train_input, train_target in train_loader:\n",
    "\n",
    "        # Model computations\n",
    "        output = model(train_input)\n",
    "        loss = criterion(output, train_target) \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tmp_acc = 0\n",
    "        for tensor, target in zip(output, train_target):\n",
    "            _, index = tensor.max(0)\n",
    "            if index == target:\n",
    "                tmp_acc += 1\n",
    "                \n",
    "        tmp_acc /= len(output)\n",
    "        acc += tmp_acc \n",
    "        \n",
    "    acc /= len(train_loader)\n",
    "        \n",
    "    should_print = e%1 == 0\n",
    "    if should_print:\n",
    "        print('%dth epoch, train acc: %f' % (e+1, acc), end=\"\")\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "    acc = 0\n",
    "    model.eval()\n",
    "    for test_input, test_target in test_loader:\n",
    "        \n",
    "        output = model(test_input)\n",
    "        loss = criterion(output, test_target) \n",
    "        \n",
    "        tmp_acc = 0\n",
    "        for tensor, target in zip(output, test_target):\n",
    "            _, index = tensor.max(0)\n",
    "            if index == target:\n",
    "                tmp_acc += 1\n",
    "#             elif should_print:\n",
    "#                 pass\n",
    "#                 print(\", {} != {}\".format(index, target), end=\"\")\n",
    "                \n",
    "        tmp_acc /= len(output)\n",
    "        acc += tmp_acc \n",
    "                \n",
    "    acc /= len(test_loader)\n",
    "    print(\", val acc: %f\" % (acc), end=\"\")\n",
    "    \n",
    "    test_losses.append(loss)\n",
    "    \n",
    "    test_acc = 0\n",
    "    test_acc_with_median = 0\n",
    "    classifier.model = model\n",
    "    classifier_with_median.model = model\n",
    "    for (img, label) in zip(images, labels):\n",
    "        prediction = classifier.predict(img)\n",
    "        if prediction == label:\n",
    "            test_acc += 1\n",
    "            \n",
    "        prediction = classifier_with_median.predict(img)\n",
    "        if prediction == label:\n",
    "            test_acc_with_median += 1\n",
    "\n",
    "    test_acc /= len(images)\n",
    "    test_acc_with_median /= len(images)\n",
    "    print(\", test acc: %f, test acc (with median): %f\" % (test_acc, test_acc_with_median))\n",
    "    \n",
    "    if test_acc_with_median > best_acc:\n",
    "        best_acc = test_acc_with_median\n",
    "        torch.save(model.state_dict(), \"../digit_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1th epoch, train acc: 0.408792, val acc: 0.523917, test acc: 0.000000\n",
    "# 2th epoch, train acc: 0.605125, val acc: 0.643417, test acc: 0.000000\n",
    "# 3th epoch, train acc: 0.678979, val acc: 0.713083, test acc: 0.000000\n",
    "# 4th epoch, train acc: 0.727250, val acc: 0.750083, test acc: 0.000000\n",
    "# 5th epoch, train acc: 0.762021, val acc: 0.773583, test acc: 0.000000\n",
    "# 6th epoch, train acc: 0.780417, val acc: 0.791583, test acc: 0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1th epoch, train acc: 0.338646, test acc: 0.456000\n",
    "# 2th epoch, train acc: 0.531000, test acc: 0.577000\n",
    "# 3th epoch, train acc: 0.606146, test acc: 0.632833\n",
    "# 4th epoch, train acc: 0.651458, test acc: 0.668083\n",
    "# 5th epoch, train acc: 0.683938, test acc: 0.694417\n",
    "# 6th epoch, train acc: 0.708542, test acc: 0.713000\n",
    "# 7th epoch, train acc: 0.728292, test acc: 0.729167\n",
    "# 8th epoch, train acc: 0.743021, test acc: 0.750583\n",
    "# 9th epoch, train acc: 0.755292, test acc: 0.763833\n",
    "# 10th epoch, train acc: 0.764208, test acc: 0.763917\n",
    "# 11th epoch, train acc: 0.773229, test acc: 0.778083\n",
    "# 12th epoch, train acc: 0.781708, test acc: 0.785333\n",
    "# 13th epoch, train acc: 0.786958, test acc: 0.785750\n",
    "# 14th epoch, train acc: 0.795396, test acc: 0.795500\n",
    "# 15th epoch, train acc: 0.798271, test acc: 0.791750\n",
    "# 16th epoch, train acc: 0.801896, test acc: 0.808917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
