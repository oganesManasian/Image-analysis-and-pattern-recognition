{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PIL\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = 255\n",
    "black = 0\n",
    "\n",
    "def img_tranform(fill_color):\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomRotation(360, fill=fill_color),\n",
    "\n",
    "        transforms.CenterCrop(300),\n",
    "        \n",
    "        transforms.ColorJitter(brightness=(0.8, 1), contrast=(0.45, 1)),\n",
    "\n",
    "    ])\n",
    "\n",
    "def fix_background_color(img):\n",
    "    colors = sorted(img.getcolors(), key=lambda pair: pair[0], reverse=True)\n",
    "    replace_color = colors[0][1]\n",
    "    remove_color = colors[2][1] if colors[2][1] > colors[1][1] else colors[1][1]\n",
    "\n",
    "    data = np.array(img)\n",
    "    data[data == remove_color] = replace_color\n",
    "    return PIL.Image.fromarray(data)\n",
    "\n",
    "operators_transform = transforms.Compose([\n",
    "    \n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    # Randomly scale up and down\n",
    "    transforms.RandomAffine(0, scale=(0.9, 1.1), fillcolor=white),\n",
    "    img_tranform(white),\n",
    "    \n",
    "    transforms.Lambda(fix_background_color),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "minst_transform = transforms.Compose([\n",
    "    # Scale up\n",
    "    transforms.Pad(70),\n",
    "    transforms.RandomAffine(0, scale=(2.5, 3.2), fillcolor=0),\n",
    "    \n",
    "    img_tranform(black),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Operators Dataset\n",
    "operators_dataset = datasets.ImageFolder(root='operators', transform=operators_transform)\n",
    "# operators_dataset.transform(operators_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minst Dataset\n",
    "minst_dataset = datasets.MNIST(\"\", transform=minst_transform, download=True)\n",
    "# minst_dataset.transform(minst_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(operators_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "    def __init__(self, operators_dataset, minst_dataset):\n",
    "        self.operators_dataset = operators_dataset\n",
    "        self.minst_dataset = minst_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < len(self.operators_dataset):\n",
    "            return self.operators_dataset[index]\n",
    "        else:\n",
    "            return self.minst_dataset[index - len(self.operators_dataset)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.operators_dataset) + len(self.minst_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FusionDataset(operators_dataset, minst_dataset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Net class object, which consists of 2 convolutional layers, max-pool layers and fully-connected layers\n",
    "class Conv_Net(nn.Module):\n",
    "    def __init__(self, nb_hidden=50):        \n",
    "        super(Conv_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3)  # the first convolutional layer, which processes the input image\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)  # the second convolutional layer, which gets the max-pooled set\n",
    "        self.fc1 = nn.Linear(800, nb_hidden)  # the first fully-connected layer, which gets flattened max-pooled set\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)  # the second fully-connected layer that outputs the result\n",
    "\n",
    "    # Creating the forward pass\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # The first two layers\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        \n",
    "        # The second two layers\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2)) \n",
    "        \n",
    "        # Flattening the data set for fully-connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "    \n",
    "        # The first fully-connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # The second full-connected layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x46a9f8a58>>\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x46a9f8a58>>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/henrydeclety/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "  File \"/Users/henrydeclety/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/henrydeclety/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "  File \"/Users/henrydeclety/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "    w.join()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-319-b3f64b5e79f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Learning loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "\n",
    "\n",
    "# Defining the optimizer for GD\n",
    "lr = 0.2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n",
    "\n",
    "# Defining the criterion to calculate loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "offset = int(len(train_loader) * 0.2)\n",
    "print(0)\n",
    "test, train = torch.Tensor(list(train_loader)[:offset]).view(-1, 784), torch.Tensor(list(train_loader)[offset:]).view(-1, 784)\n",
    "print(1)\n",
    "# Learning loop\n",
    "nb_epochs = 10\n",
    "mini_batch_size = 100\n",
    "for e in tqdm(range(nb_epochs)):\n",
    "    # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "    for train_input, train_target in train.split(mini_batch_size):\n",
    "\n",
    "        # Model computations\n",
    "        output = model(train_input)\n",
    "        loss = criterion(output, train_target) \n",
    "        print(\"train\", loss)\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "    for test_input, test_target in test.split(mini_batch_size):\n",
    "        \n",
    "        output = model(test_input)\n",
    "        loss = criterion(output, test_target) \n",
    "        print(\"test\", loss)\n",
    "        \n",
    "    # Validation\n",
    "#     with torch.set_grad_enabled(False):\n",
    "#         for local_batch, local_labels in validation_generator:\n",
    "#             # Transfer to GPU\n",
    "#             local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "#             # Model computations\n",
    "#             [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_inputs, train_targets, mini_batch_size=100, remember_losses=True, lr=1e-3, nb_epochs=20):\n",
    "    \n",
    "    \"\"\"\n",
    "        Train the PyTorch model on the training set.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        model : PyTorch NN object\n",
    "            PyTorch neural network model      \n",
    "        train_inputs : torch.Tensor object\n",
    "            The input train feature set\n",
    "        train_targets : torch.Tensor object\n",
    "            The input train label set\n",
    "        mini_batch_size : int\n",
    "            The size of the batch processing size\n",
    "        remember_losses : boolean\n",
    "            True if remember losses for model evaluation, False if not\n",
    "        lr : float\n",
    "            Learning rate for the model training\n",
    "        nb_epochs : int\n",
    "            The number of epochs used to train the model\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        NN object or (NN object, list)\n",
    "            If remember_losses is True then the function returns both\n",
    "            the trained model and the list of losses for each epoch. \n",
    "            If remember_losses is False then the function return only\n",
    "            the trained model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining the learning rate and number of epochs\n",
    "    losses = []\n",
    "\n",
    "    # Defining the optimizer for GD\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n",
    "    \n",
    "    # Defining the criterion to calculate loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Learning loop\n",
    "    for e in range(nb_epochs):\n",
    "        # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "        for train_input, train_target in zip(train_inputs.split(mini_batch_size), train_targets.split(mini_batch_size)):\n",
    "            output = model(train_input)\n",
    "            loss = criterion(output, train_target) \n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(loss)\n",
    "        print('%dth epoch is finished and the loss is %f' % (e+1, loss))\n",
    "           \n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
