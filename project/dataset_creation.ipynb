{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PIL\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = 255\n",
    "black = 0\n",
    "\n",
    "def inverse_color(img):\n",
    "    return PIL.Image.eval(img, lambda val: 255 - val)\n",
    "\n",
    "def fix_background_color_bug(img):\n",
    "    colors = sorted(img.getcolors(), key=lambda pair: pair[0], reverse=True)\n",
    "    replace_color = colors[0][1]\n",
    "    remove_color = colors[2][1] if colors[2][1] > colors[1][1] else colors[1][1]\n",
    "\n",
    "    data = np.array(img)\n",
    "    data[data == remove_color] = replace_color\n",
    "    return PIL.Image.fromarray(data)\n",
    "\n",
    "def to_binary(img):\n",
    "    return PIL.Image.eval(img, lambda val: 255 if val < (256/2) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_image = True\n",
    "\n",
    "\n",
    "## Rotation, Brightness and Resizing\n",
    "common_transforms = [\n",
    "    transforms.RandomRotation(360, fill=black),\n",
    "    #         transforms.CenterCrop(300),\n",
    "    transforms.Resize((30, 30)),\n",
    "]\n",
    "\n",
    "if not binary_image:\n",
    "    common_transforms.append(transforms.ColorJitter(brightness=(0.8, 1), contrast=(0.45, 1)))\n",
    "else:\n",
    "    common_transforms.append(transforms.Lambda(to_binary))\n",
    "\n",
    "common_transform = transforms.Compose(common_transforms)\n",
    "\n",
    "\n",
    "## Adding Grayscale + Inverse color to operators\n",
    "operators_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Lambda(inverse_color),\n",
    "    # Randomly scale up and down\n",
    "#     transforms.RandomAffine(0, scale=(0.9, 1.1), fillcolor=white),\n",
    "    common_transform,\n",
    "])\n",
    "\n",
    "operators_tensor_transform = transforms.Compose([\n",
    "    operators_transform,\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "minst_tensor_transform = transforms.Compose([\n",
    "    common_transform,\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAAAAAAeW/F+AAAAdklEQVR4nLXSUQ6AIAwD0JV4/yvXDxmwURYTowkf7jkoIGjV00r9yJcqwoznbvRhZuCocFF/bbOCV9FQsiszc9fOpFZPLmfOa28aWOxMnRol71OvrHRyUCBx1PFB01ol39aOsfTGUuinb/4tQr2bWtONnbr/4Rts3x04cXCCtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=30x30 at 0x1333D5E10>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operators Dataset\n",
    "operators_dataset = datasets.ImageFolder(root='operators', transform=operators_tensor_transform)\n",
    "\n",
    "# Show exemple image\n",
    "datasets.ImageFolder(root='operators', transform=operators_transform)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAAAAAAeW/F+AAAAd0lEQVR4nNWSQRLAIAgDs47//3J6qLaCjOfWk8MGggjW6bQj/TLuOYC0vDVlw604Focaky9dYjXzYCPYQpKFZmsMbK/NSJI9eZvNsAsYOHk/AuJYkocEjiBsB9O73hk7znxTtUdY5r9DLfkycxetxy/ZKvDbPb8A0sEdP7FCBqYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=30x30 at 0x1333D5CF8>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minst Dataset\n",
    "minst_dataset = datasets.MNIST(\"\", transform=minst_tensor_transform, download=True)\n",
    "\n",
    "# Show example image\n",
    "datasets.MNIST(\"\", transform=common_transform, download=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=50,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "\n",
    "    mean /= len(loader.dataset)\n",
    "    std /= len(loader.dataset)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6462]), tensor([0.4699]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operators_mean, operators_std = get_stats(operators_dataset)\n",
    "operators_mean, operators_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8694]), tensor([0.3303]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minst_mean, minst_std = get_stats(minst_dataset)\n",
    "minst_mean, minst_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionDataset(datasets.VisionDataset):\n",
    "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "    def __init__(self, operators_dataset, minst_dataset):\n",
    "        self.operators_dataset = operators_dataset\n",
    "        self.minst_dataset = minst_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < len(self.operators_dataset):\n",
    "            tensor, class_index = self.operators_dataset[index]   \n",
    "            tensor = transforms.Normalize(operators_mean, operators_std)(tensor)\n",
    "            return tensor, class_index + 10\n",
    "        else:\n",
    "            tensor, class_index = self.minst_dataset[index - len(self.operators_dataset)]\n",
    "            tensor = transforms.Normalize(minst_mean, minst_std)(tensor)\n",
    "            return tensor, class_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.minst_dataset) + len(self.operators_dataset)\n",
    "    \n",
    "def get_loaders(dataset, batch_size=100, validation_split=0.2, shuffle_dataset=True):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset:\n",
    "        np.random.seed(randint(0, 100))\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "    \n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FusionDataset(operators_dataset, minst_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.7548e-05]), tensor([1.0000]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std = get_stats(dataset)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Net class object, which consists of 2 convolutional layers, max-pool layers and fully-connected layers\n",
    "class Conv_Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_hidden=50):        \n",
    "        super(Conv_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3)  # the first convolutional layer, which processes the input image\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)  # the second convolutional layer, which gets the max-pooled set\n",
    "        self.fc1 = nn.Linear(1152, nb_hidden)  # the first fully-connected layer, which gets flattened max-pooled set\n",
    "        self.fc2 = nn.Linear(nb_hidden, 15)  # the second fully-connected layer that outputs the result\n",
    "\n",
    "    # Creating the forward pass\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # The first two layers\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        \n",
    "        # The second two layers\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2)) \n",
    "        \n",
    "        # Flattening the data set for fully-connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "    \n",
    "        # The first fully-connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # The second full-connected layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th epoch is finished and the loss is 0.561357\n",
      "test loss: 3.942132, acc: 0.589421\n",
      "2th epoch is finished and the loss is 1.394782\n",
      "test loss: 0.327267, acc: 0.708347\n",
      "3th epoch is finished and the loss is 0.324581\n",
      "test loss: 1.049312, acc: 0.751901\n",
      "4th epoch is finished and the loss is 0.518378\n",
      "test loss: 0.732578, acc: 0.789339\n",
      "5th epoch is finished and the loss is 0.632969\n",
      "test loss: 3.683100, acc: 0.806198\n",
      "6th epoch is finished and the loss is 0.540124\n",
      "test loss: 0.536292, acc: 0.834545\n",
      "7th epoch is finished and the loss is 0.368760\n",
      "test loss: 0.083647, acc: 0.841983\n",
      "8th epoch is finished and the loss is 1.927319\n",
      "test loss: 0.030339, acc: 0.856281\n",
      "9th epoch is finished and the loss is 0.010527\n",
      "test loss: 0.061796, acc: 0.866942\n",
      "10th epoch is finished and the loss is 0.278621\n",
      "test loss: 0.035545, acc: 0.862397\n",
      "11th epoch is finished and the loss is 0.067737\n",
      "test loss: 0.102889, acc: 0.879008\n",
      "12th epoch is finished and the loss is 0.373472\n",
      "test loss: 0.291908, acc: 0.882066\n",
      "13th epoch is finished and the loss is 0.008670\n",
      "test loss: 0.002032, acc: 0.885124\n",
      "14th epoch is finished and the loss is 0.013968\n",
      "test loss: 0.038664, acc: 0.894132\n",
      "15th epoch is finished and the loss is 0.334004\n",
      "test loss: 0.051721, acc: 0.892397\n",
      "16th epoch is finished and the loss is 0.416110\n",
      "test loss: 0.004166, acc: 0.897355\n",
      "17th epoch is finished and the loss is 0.043772\n",
      "test loss: 0.131505, acc: 0.901653\n",
      "18th epoch is finished and the loss is 0.627294\n",
      "test loss: 0.006626, acc: 0.905785\n",
      "19th epoch is finished and the loss is 0.240986\n",
      "test loss: 0.022489, acc: 0.907686\n",
      "20th epoch is finished and the loss is 0.118951\n",
      "test loss: 0.171477, acc: 0.907686\n",
      "21th epoch is finished and the loss is 1.205787\n",
      "test loss: 0.000742, acc: 0.914628\n",
      "22th epoch is finished and the loss is 0.088968\n",
      "test loss: 0.577433, acc: 0.911818\n",
      "23th epoch is finished and the loss is 0.083356\n",
      "test loss: 0.277048, acc: 0.912727\n",
      "24th epoch is finished and the loss is 2.271804\n",
      "test loss: 0.055849, acc: 0.913636\n",
      "25th epoch is finished and the loss is 0.040465\n",
      "test loss: 0.027343, acc: 0.921074\n",
      "26th epoch is finished and the loss is 0.287025\n",
      "test loss: 0.004259, acc: 0.917025\n",
      "27th epoch is finished and the loss is 0.772102\n",
      "test loss: 0.092416, acc: 0.917521\n",
      "28th epoch is finished and the loss is 0.198610\n",
      "test loss: 0.158630, acc: 0.917603\n",
      "29th epoch is finished and the loss is 0.101779\n",
      "test loss: 0.003221, acc: 0.919091\n",
      "30th epoch is finished and the loss is 0.477445\n",
      "test loss: 0.024847, acc: 0.922727\n",
      "CPU times: user 3h 12min 6s, sys: 40min 16s, total: 3h 52min 22s\n",
      "Wall time: 56min 44s\n",
      "Parser   : 114 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Conv_Net()\n",
    "train_loader, test_loader = get_loaders(dataset)\n",
    "\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Defining the optimizer for GD\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr) \n",
    "\n",
    "# Defining the criterion to calculate loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "nb_epochs = 30\n",
    "\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "    for train_input, train_target in train_loader:\n",
    "\n",
    "        # Model computations\n",
    "        output = model(train_input)\n",
    "        loss = criterion(output, train_target) \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('%dth epoch is finished and the loss is %f' % (e+1, loss))\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Train the input dataset by dividing it into mini_batch_size small datasets\n",
    "    acc = 0\n",
    "    for test_input, test_target in test_loader:\n",
    "        \n",
    "        output = model(test_input)\n",
    "        loss = criterion(output, test_target) \n",
    "        \n",
    "        tmp_acc = 0\n",
    "        for tensor, target in zip(output, test_target):\n",
    "            _, index = tensor.max(0)\n",
    "            if index == target:\n",
    "                tmp_acc += 1\n",
    "                \n",
    "        tmp_acc /= len(output)\n",
    "        acc += tmp_acc \n",
    "                \n",
    "    acc /= len(test_loader)\n",
    "    print(\"test loss: %f, acc: %f\" % (loss, acc))\n",
    "    test_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
